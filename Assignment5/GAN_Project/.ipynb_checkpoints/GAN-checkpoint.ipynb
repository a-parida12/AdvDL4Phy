{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from Vel2Img import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data set\n",
    "with open('./data/velocity.pickle', 'rb') as handle:\n",
    "    velocities = pickle.load(handle)\n",
    "\n",
    "for i in range(velocities.shape[0]):\n",
    "    velocities[i,:,:,:]=(velocities[i,:,:,:]-velocities[i,:,:,:].min())/(velocities[i,:,:,:].max()-velocities[i,:,:,:].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocities[1,:,:,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the discriminator\n",
    "\n",
    "def convolution2d(input, biases, weights, strides, padding_kind='SAME'):\n",
    "    input = tf.nn.conv2d(input, weights, [1,strides,strides,1], padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    input = tf.nn.leaky_relu(input)\n",
    "    return input\n",
    "\n",
    "def discriminator(x_image):\n",
    "    \n",
    "    #layer1: Convolution\n",
    "    weights1=tf.Variable(tf.random_normal([12,12,2,2], stddev=0.01),name='d_Wconv1')\n",
    "    #[filter_height, filter_width, in_channels, out_channels]\n",
    "    #bias=out_channels\n",
    "    bias1=tf.Variable(tf.random_normal([2],stddev=0.01), name='d_Bconv1')\n",
    "    stride1=2\n",
    "    out1=convolution2d(x_image,bias1,weights1,stride1)\n",
    "    print(out1.shape)\n",
    "    #layer2: Convolution\n",
    "    weights2=tf.Variable(tf.random_normal([6,6,2,4], stddev=0.01),name='d_Wconv2')\n",
    "    bias2=tf.Variable(tf.random_normal([4], stddev=0.01),name='d_Bconv2')\n",
    "    stride2=4\n",
    "    out2=convolution2d(out1,bias2,weights2,stride2)\n",
    "    print(out2.shape)\n",
    "    #layer3: Convolution\n",
    "    weights3=tf.Variable(tf.random_normal([4,4,4,8],stddev=0.01), name='d_Wconv3')\n",
    "    bias3=tf.Variable(tf.random_normal([8],stddev=0.01), name='d_Bconv3')\n",
    "    stride3=2\n",
    "    out3=convolution2d(out2,bias3,weights3,stride3)\n",
    "    print(out3.shape)\n",
    "    #layer4: Convolution\n",
    "    weights4=tf.Variable(tf.random_normal([3,3,8,16], stddev=0.01),name='d_Wconv4')#weights==filters\n",
    "    bias4=tf.Variable(tf.random_normal([16], stddev=0.01),name='d_Bconv4')\n",
    "    stride4=2\n",
    "    out4=convolution2d(out3,bias4,weights4,stride4)\n",
    "    print(out4.shape)\n",
    "    #layer5: Fully Connected Layer\n",
    "    out4 = tf.reshape(out4, shape=[-1, 64 ]) # flatten\n",
    "    fc_1weights = tf.Variable(tf.random_normal([64, 1],stddev=0.01), name='d_WFCN1')\n",
    "    fc_1bias   = tf.Variable(tf.random_normal([1], stddev=0.01),name='d_BFCN1')\n",
    "    fc1 = tf.add(tf.matmul(out4, fc_1weights), fc_1bias)\n",
    "    fc1 = tf.nn.sigmoid(fc1)\n",
    "    \n",
    "    return fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the Generator\n",
    "\n",
    "def deconvolution2d(input, weights, biases,outputShape, strides, padding_kind='SAME',activation='sigmoid'):\n",
    "    # needed for dynamic shape with deconvolution\n",
    "    dynamicBatchSize = tf.shape(input)[0]\n",
    "    deconvShape = tf.stack([dynamicBatchSize, outputShape[1], outputShape[2], outputShape[3]])\n",
    "    input = tf.nn.conv2d_transpose(input, weights, deconvShape, [1,strides,strides,1], padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    if activation =='leaky':\n",
    "        input = tf.nn.leaky_relu(input)\n",
    "    elif activation=='tanh':\n",
    "        input = tf.nn.tanh(input)\n",
    "    elif activation=='sigmoid':\n",
    "        input = tf.nn.sigmoid(input)\n",
    "    return input\n",
    "\n",
    "def generator(noise):\n",
    "    #layer1: DeConvolution\n",
    "    weights5=tf.Variable(tf.random_normal([3,3,8,16],stddev=0.1), name='g_Wdeconv1')#weights==filters\n",
    "    #[filter_height, filter_width, in_channels, out_channels]\n",
    "    #bias=out_channels\n",
    "    bias5=tf.Variable(tf.random_normal([8], stddev=0.1),name='g_Bdeconv1')\n",
    "    stride5=2\n",
    "    deconv1=deconvolution2d(noise,weights5,bias5,[None, 4,4, 8],stride5)\n",
    "\n",
    "    #layer2: DeConvolution\n",
    "    weights6=tf.Variable(tf.random_normal([4,4,4,8], stddev=0.1),name='g_Wdeconv2')#weights==filters\n",
    "    bias6=tf.Variable(tf.random_normal([4],stddev=0.1), name='g_Bdeconv2')\n",
    "    stride6=2\n",
    "    deconv2=deconvolution2d(deconv1,weights6,bias6,[None, 8,8, 4],stride6)\n",
    "\n",
    "    #layer3: DeConvolution\n",
    "    weights7=tf.Variable(tf.random_normal([6,6,2,4], stddev=0.1), name='g_Wdeconv3')#weights==filters\n",
    "    bias7=tf.Variable(tf.random_normal([2], stddev=0.1), name='g_Bdeconv3')\n",
    "    stride7=4\n",
    "    deconv3=deconvolution2d(deconv2,weights7,bias7,[None, 32,32, 2],stride7)\n",
    "\n",
    "    #layer4: DeConvolution\n",
    "    weights8=tf.Variable(tf.random_normal([12,12,2,2], stddev=0.1),name='g_Wdeconv4')#weights==filters\n",
    "    bias8=tf.Variable(tf.random_normal([2], stddev=0.1), name='g_Bdeconv4')\n",
    "    stride8=2\n",
    "    xOut=deconvolution2d(deconv3,weights8,bias8,[None, 64,64, 2],stride8,activation='sigmoid')# based on GANHacks\n",
    "    \n",
    "    return xOut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "batch_size = 10\n",
    "sess = tf.Session()\n",
    "ImageInput = tf.placeholder(tf.float32,shape = [None, 64,64, 2])\n",
    "NoiseInput = tf.placeholder(tf.float32,shape=[None, 2,2, 16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 2)\n",
      "(?, 8, 8, 4)\n",
      "(?, 4, 4, 8)\n",
      "(?, 2, 2, 16)\n",
      "(?, 32, 32, 2)\n",
      "(?, 8, 8, 4)\n",
      "(?, 4, 4, 8)\n",
      "(?, 2, 2, 16)\n"
     ]
    }
   ],
   "source": [
    "GeneratedImage = generator(NoiseInput) #GeneratedImage holds the generated images\n",
    "\n",
    "RealImages = discriminator(ImageInput) #holds discriminator outputs (unnormalized) for the real images\n",
    "FakeImages = discriminator(GeneratedImage) #will hold the discriminator output (unnormalized) for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Loss\n",
    "Generator_loss = -tf.reduce_mean(tf.log(FakeImages))\n",
    "\n",
    "Discriminator_loss= -tf.reduce_mean(tf.log(RealImages) + tf.log(1. - FakeImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate each network variables\n",
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-4\n",
    "# Create the Optimiser\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# Create training operations on the repective netork variable only\n",
    "train_gen = optimizer_gen.minimize(Generator_loss, var_list=g_vars)\n",
    "train_disc = optimizer_disc.minimize(Discriminator_loss, var_list=d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1: Generator Loss: 0.691128, Discriminator Loss: 1.382547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a_parida/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "/home/a_parida/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Generator Loss: 0.691207, Discriminator Loss: 1.382382\n",
      "Epoch 3: Generator Loss: 0.691286, Discriminator Loss: 1.382216\n",
      "Epoch 4: Generator Loss: 0.691363, Discriminator Loss: 1.382052\n",
      "Epoch 5: Generator Loss: 0.691441, Discriminator Loss: 1.381887\n",
      "Epoch 6: Generator Loss: 0.691518, Discriminator Loss: 1.381722\n",
      "Epoch 7: Generator Loss: 0.691595, Discriminator Loss: 1.381558\n",
      "Epoch 8: Generator Loss: 0.691672, Discriminator Loss: 1.381395\n",
      "Epoch 9: Generator Loss: 0.691749, Discriminator Loss: 1.381232\n",
      "Epoch 10: Generator Loss: 0.691826, Discriminator Loss: 1.381069\n",
      "Epoch 11: Generator Loss: 0.691902, Discriminator Loss: 1.380906\n",
      "Epoch 12: Generator Loss: 0.691978, Discriminator Loss: 1.380742\n",
      "Epoch 13: Generator Loss: 0.692055, Discriminator Loss: 1.380578\n",
      "Epoch 14: Generator Loss: 0.692131, Discriminator Loss: 1.380414\n",
      "Epoch 15: Generator Loss: 0.692208, Discriminator Loss: 1.380249\n",
      "Epoch 16: Generator Loss: 0.692284, Discriminator Loss: 1.380084\n",
      "Epoch 17: Generator Loss: 0.692361, Discriminator Loss: 1.379918\n",
      "Epoch 18: Generator Loss: 0.692439, Discriminator Loss: 1.379752\n",
      "Epoch 19: Generator Loss: 0.692516, Discriminator Loss: 1.379584\n",
      "Epoch 20: Generator Loss: 0.692594, Discriminator Loss: 1.379415\n",
      "Epoch 21: Generator Loss: 0.692673, Discriminator Loss: 1.379246\n",
      "Epoch 22: Generator Loss: 0.692752, Discriminator Loss: 1.379075\n",
      "Epoch 23: Generator Loss: 0.692831, Discriminator Loss: 1.378902\n",
      "Epoch 24: Generator Loss: 0.692911, Discriminator Loss: 1.378729\n",
      "Epoch 25: Generator Loss: 0.692992, Discriminator Loss: 1.378554\n",
      "Epoch 26: Generator Loss: 0.693073, Discriminator Loss: 1.378378\n",
      "Epoch 27: Generator Loss: 0.693155, Discriminator Loss: 1.378200\n",
      "Epoch 28: Generator Loss: 0.693239, Discriminator Loss: 1.378020\n",
      "Epoch 29: Generator Loss: 0.693323, Discriminator Loss: 1.377838\n",
      "Epoch 30: Generator Loss: 0.693408, Discriminator Loss: 1.377653\n",
      "Epoch 31: Generator Loss: 0.693495, Discriminator Loss: 1.377466\n",
      "Epoch 32: Generator Loss: 0.693584, Discriminator Loss: 1.377276\n",
      "Epoch 33: Generator Loss: 0.693674, Discriminator Loss: 1.377082\n",
      "Epoch 34: Generator Loss: 0.693766, Discriminator Loss: 1.376886\n",
      "Epoch 35: Generator Loss: 0.693860, Discriminator Loss: 1.376685\n",
      "Epoch 36: Generator Loss: 0.693956, Discriminator Loss: 1.376481\n",
      "Epoch 37: Generator Loss: 0.694055, Discriminator Loss: 1.376271\n",
      "Epoch 38: Generator Loss: 0.694156, Discriminator Loss: 1.376057\n",
      "Epoch 39: Generator Loss: 0.694260, Discriminator Loss: 1.375839\n",
      "Epoch 40: Generator Loss: 0.694367, Discriminator Loss: 1.375615\n",
      "Epoch 41: Generator Loss: 0.694477, Discriminator Loss: 1.375383\n",
      "Epoch 42: Generator Loss: 0.694591, Discriminator Loss: 1.375145\n",
      "Epoch 43: Generator Loss: 0.694709, Discriminator Loss: 1.374903\n",
      "Epoch 44: Generator Loss: 0.694832, Discriminator Loss: 1.374651\n",
      "Epoch 45: Generator Loss: 0.694959, Discriminator Loss: 1.374389\n",
      "Epoch 46: Generator Loss: 0.695092, Discriminator Loss: 1.374120\n",
      "Epoch 47: Generator Loss: 0.695231, Discriminator Loss: 1.373839\n",
      "Epoch 48: Generator Loss: 0.695375, Discriminator Loss: 1.373550\n",
      "Epoch 49: Generator Loss: 0.695525, Discriminator Loss: 1.373255\n",
      "Epoch 50: Generator Loss: 0.695684, Discriminator Loss: 1.372945\n",
      "Epoch 51: Generator Loss: 0.695850, Discriminator Loss: 1.372614\n",
      "Epoch 52: Generator Loss: 0.696026, Discriminator Loss: 1.372277\n",
      "Epoch 53: Generator Loss: 0.696211, Discriminator Loss: 1.371915\n",
      "Epoch 54: Generator Loss: 0.696408, Discriminator Loss: 1.371546\n",
      "Epoch 55: Generator Loss: 0.696616, Discriminator Loss: 1.371143\n",
      "Epoch 56: Generator Loss: 0.696834, Discriminator Loss: 1.370741\n",
      "Epoch 57: Generator Loss: 0.697066, Discriminator Loss: 1.370294\n",
      "Epoch 58: Generator Loss: 0.697314, Discriminator Loss: 1.369839\n",
      "Epoch 59: Generator Loss: 0.697577, Discriminator Loss: 1.369371\n",
      "Epoch 60: Generator Loss: 0.697858, Discriminator Loss: 1.368834\n",
      "Epoch 61: Generator Loss: 0.698157, Discriminator Loss: 1.368299\n",
      "Epoch 62: Generator Loss: 0.698477, Discriminator Loss: 1.367725\n",
      "Epoch 63: Generator Loss: 0.698819, Discriminator Loss: 1.367124\n",
      "Epoch 64: Generator Loss: 0.699184, Discriminator Loss: 1.366491\n",
      "Epoch 65: Generator Loss: 0.699574, Discriminator Loss: 1.365794\n",
      "Epoch 66: Generator Loss: 0.699991, Discriminator Loss: 1.365081\n",
      "Epoch 67: Generator Loss: 0.700438, Discriminator Loss: 1.364242\n",
      "Epoch 68: Generator Loss: 0.700915, Discriminator Loss: 1.363456\n",
      "Epoch 69: Generator Loss: 0.701427, Discriminator Loss: 1.362534\n",
      "Epoch 70: Generator Loss: 0.701974, Discriminator Loss: 1.361581\n",
      "Epoch 71: Generator Loss: 0.702560, Discriminator Loss: 1.360598\n",
      "Epoch 72: Generator Loss: 0.703188, Discriminator Loss: 1.359506\n",
      "Epoch 73: Generator Loss: 0.703859, Discriminator Loss: 1.358324\n",
      "Epoch 74: Generator Loss: 0.704578, Discriminator Loss: 1.357261\n",
      "Epoch 75: Generator Loss: 0.705348, Discriminator Loss: 1.355941\n",
      "Epoch 76: Generator Loss: 0.706172, Discriminator Loss: 1.354539\n",
      "Epoch 77: Generator Loss: 0.707052, Discriminator Loss: 1.353096\n",
      "Epoch 78: Generator Loss: 0.707994, Discriminator Loss: 1.351606\n",
      "Epoch 79: Generator Loss: 0.709001, Discriminator Loss: 1.349930\n",
      "Epoch 80: Generator Loss: 0.710077, Discriminator Loss: 1.348073\n",
      "Epoch 81: Generator Loss: 0.711224, Discriminator Loss: 1.346288\n",
      "Epoch 82: Generator Loss: 0.712448, Discriminator Loss: 1.344253\n",
      "Epoch 83: Generator Loss: 0.713755, Discriminator Loss: 1.342246\n",
      "Epoch 84: Generator Loss: 0.715150, Discriminator Loss: 1.339702\n",
      "Epoch 85: Generator Loss: 0.716637, Discriminator Loss: 1.337320\n",
      "Epoch 86: Generator Loss: 0.718223, Discriminator Loss: 1.334607\n",
      "Epoch 87: Generator Loss: 0.719909, Discriminator Loss: 1.332037\n",
      "Epoch 88: Generator Loss: 0.721704, Discriminator Loss: 1.329146\n",
      "Epoch 89: Generator Loss: 0.723614, Discriminator Loss: 1.325697\n",
      "Epoch 90: Generator Loss: 0.725646, Discriminator Loss: 1.322846\n",
      "Epoch 91: Generator Loss: 0.727805, Discriminator Loss: 1.319415\n",
      "Epoch 92: Generator Loss: 0.730099, Discriminator Loss: 1.315983\n",
      "Epoch 93: Generator Loss: 0.732535, Discriminator Loss: 1.312076\n",
      "Epoch 94: Generator Loss: 0.735120, Discriminator Loss: 1.308385\n",
      "Epoch 95: Generator Loss: 0.737862, Discriminator Loss: 1.303753\n",
      "Epoch 96: Generator Loss: 0.740769, Discriminator Loss: 1.299151\n",
      "Epoch 97: Generator Loss: 0.743849, Discriminator Loss: 1.293849\n",
      "Epoch 98: Generator Loss: 0.747111, Discriminator Loss: 1.288988\n",
      "Epoch 99: Generator Loss: 0.750564, Discriminator Loss: 1.283733\n",
      "Epoch 100: Generator Loss: 0.754218, Discriminator Loss: 1.277881\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "trainingEpochs=100\n",
    "batchSize= 100\n",
    "loadNum = len(velocities)\n",
    "#creating Seesion starting training\n",
    "print(\"Starting training...\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# lets train for all epochs\n",
    "for epoch in range(1,trainingEpochs+1):\n",
    "    batch = []\n",
    "    for currNo in range(0, batchSize):\n",
    "        r = random.randint(0, loadNum-1)\n",
    "        batch.append( velocities[r] )\n",
    "        \n",
    "    # Generate noise to feed to the generator\n",
    "    z = np.random.uniform(-1., 1., size=[batchSize, 2,2,16])\n",
    "        \n",
    "    # Train\n",
    "    fed_dict = {ImageInput: batch, NoiseInput: z}\n",
    "    t,_, _, gl, dl = sess.run([GeneratedImage,train_gen, train_disc, Generator_loss, Discriminator_loss],\n",
    "                                feed_dict=fed_dict)\n",
    "\n",
    "    if epoch % 1 == 0 or epoch == 1:\n",
    "        print('Epoch %i: Generator Loss: %f, Discriminator Loss: %f' % (epoch, gl, dl))\n",
    "\n",
    "        outDir = \"./Progress/\"\n",
    "        if not os.path.exists(outDir): \n",
    "            os.makedirs(outDir)   \n",
    "        r = random.randint(0, batchSize-1)\n",
    "        scipy.misc.toimage(np.reshape(z[r,:,:,:],(8,8)) , cmin=0.0, cmax=1.0).save(\"%s/noise_%d.png\" % (outDir,epoch))\n",
    "       # g = sess.run([GeneratedImage], feed_dict={NoiseInput:z[r:r+1,:,:,:] })\n",
    "        g = np.reshape(t[r], newshape=( 64, 64, 2))\n",
    "        generatedImage=velocityFieldToPng(g)\n",
    "\n",
    "        scipy.misc.toimage( np.reshape(generatedImage, [64, 64, 3]) , cmin=0.0, cmax=1.0).save(outDir+'/genImg_'+str(epoch)+'.png')\n",
    "\n",
    "print(\"Done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No. Learnable Parameters for the GAN: 7790\n"
     ]
    }
   ],
   "source": [
    "###Counting the learnable parameters\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    #print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(\"Total No. Learnable Parameters for the GAN:\",total_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'g_Wdeconv1:0' shape=(3, 3, 8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'g_Bdeconv1:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'g_Wdeconv2:0' shape=(4, 4, 4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'g_Bdeconv2:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'g_Wdeconv3:0' shape=(6, 6, 2, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'g_Bdeconv3:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'g_Wdeconv4:0' shape=(12, 12, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'g_Bdeconv4:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Wconv1:0' shape=(12, 12, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Bconv1:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Wconv2:0' shape=(6, 6, 2, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Bconv2:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Wconv3:0' shape=(4, 4, 4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Bconv3:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Wconv4:0' shape=(3, 3, 8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Bconv4:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_WFCN1:0' shape=(64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'd_BFCN1:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Wconv1_1:0' shape=(12, 12, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Bconv1_1:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Wconv2_1:0' shape=(6, 6, 2, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Bconv2_1:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Wconv3_1:0' shape=(4, 4, 4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Bconv3_1:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Wconv4_1:0' shape=(3, 3, 8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'd_Bconv4_1:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'd_WFCN1_1:0' shape=(64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'd_BFCN1_1:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
