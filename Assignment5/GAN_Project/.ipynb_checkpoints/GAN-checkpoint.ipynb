{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from Vel2Img import *\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#load the data set\n",
    "with open('./data/velocity.pickle', 'rb') as handle:\n",
    "    velocities = pickle.load(handle)\n",
    "\n",
    "for i in range(velocities.shape[0]):\n",
    "    velocities[i,:,:,:]=(velocities[i,:,:,:]-velocities[i,:,:,:].min())/(velocities[i,:,:,:].max()-velocities[i,:,:,:].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "velocities[1,:,:,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the discriminator\n",
    "\n",
    "def convolution2d(input, biases, weights, strides, padding_kind='SAME'):\n",
    "    input = tf.nn.conv2d(input, weights, [1,strides,strides,1], padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    input = tf.nn.leaky_relu(input)\n",
    "    return input\n",
    "\n",
    "def discriminator(x_image):\n",
    "    \n",
    "    #layer1: Convolution\n",
    "    weights1=tf.Variable(tf.random_normal([12,12,2,2], stddev=0.01),name='d_Wconv1')\n",
    "    #[filter_height, filter_width, in_channels, out_channels]\n",
    "    #bias=out_channels\n",
    "    bias1=tf.Variable(tf.random_normal([2],stddev=0.01), name='d_Bconv1')\n",
    "    stride1=2\n",
    "    out1=convolution2d(x_image,bias1,weights1,stride1)\n",
    "    print(out1.shape)\n",
    "    #layer2: Convolution\n",
    "    weights2=tf.Variable(tf.random_normal([6,6,2,4], stddev=0.01),name='d_Wconv2')\n",
    "    bias2=tf.Variable(tf.random_normal([4], stddev=0.01),name='d_Bconv2')\n",
    "    stride2=4\n",
    "    out2=convolution2d(out1,bias2,weights2,stride2)\n",
    "    print(out2.shape)\n",
    "    #layer3: Convolution\n",
    "    weights3=tf.Variable(tf.random_normal([4,4,4,8],stddev=0.01), name='d_Wconv3')\n",
    "    bias3=tf.Variable(tf.random_normal([8],stddev=0.01), name='d_Bconv3')\n",
    "    stride3=2\n",
    "    out3=convolution2d(out2,bias3,weights3,stride3)\n",
    "    print(out3.shape)\n",
    "    #layer4: Convolution\n",
    "    weights4=tf.Variable(tf.random_normal([3,3,8,16], stddev=0.01),name='d_Wconv4')#weights==filters\n",
    "    bias4=tf.Variable(tf.random_normal([16], stddev=0.01),name='d_Bconv4')\n",
    "    stride4=2\n",
    "    out4=convolution2d(out3,bias4,weights4,stride4)\n",
    "    print(out4.shape)\n",
    "    #layer5: Fully Connected Layer\n",
    "    out4 = tf.reshape(out4, shape=[-1, 64 ]) # flatten\n",
    "    fc_1weights = tf.Variable(tf.random_normal([64, 8],stddev=0.01), name='d_WFCN1')\n",
    "    fc_1bias   = tf.Variable(tf.random_normal([8], stddev=0.01),name='d_BFCN1')\n",
    "    fc1 = tf.add(tf.matmul(out4, fc_1weights), fc_1bias)\n",
    "    fc1 = tf.nn.tanh(fc1)\n",
    "    \n",
    "    #layer6: Fully Connected Layer\n",
    "    fc_2weights = tf.Variable(tf.random_normal([8, 1],stddev=0.01), name='d_WFCN2')\n",
    "    fc_2bias   = tf.Variable(tf.random_normal([1], stddev=0.01),name='d_BFCN2')\n",
    "    fc2 = tf.add(tf.matmul(fc1, fc_2weights), fc_1bias)\n",
    "    fc2 = tf.nn.sigmoid(fc2)\n",
    "    \n",
    "    return fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the Generator\n",
    "\n",
    "def deconvolution2d(input, weights, biases,outputShape, strides, padding_kind='SAME',activation='sigmoid'):\n",
    "    # needed for dynamic shape with deconvolution\n",
    "    dynamicBatchSize = tf.shape(input)[0]\n",
    "    deconvShape = tf.stack([dynamicBatchSize, outputShape[1], outputShape[2], outputShape[3]])\n",
    "    input = tf.nn.conv2d_transpose(input, weights, deconvShape, [1,strides,strides,1], padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    if activation =='leaky':\n",
    "        input = tf.nn.leaky_relu(input)\n",
    "    elif activation=='tanh':\n",
    "        input = tf.nn.tanh(input)\n",
    "    elif activation=='sigmoid':\n",
    "        input = tf.nn.sigmoid(input)\n",
    "    return input\n",
    "\n",
    "def generator(noise):\n",
    "    \n",
    "    #layer1: DeConvolution\n",
    "    weights5=tf.Variable(tf.random_normal([6,6,256,16],stddev=0.1), name='g_Wdeconv1')#weights==filters\n",
    "    #[filter_height, filter_width, out_channels, in_channels]\n",
    "    #bias=out_channels\n",
    "    bias5=tf.Variable(tf.random_normal([256], stddev=0.1),name='g_Bdeconv1')\n",
    "    stride5=2#facror of upscale\n",
    "    deconv1=deconvolution2d(noise,weights5,bias5,[None, 4,4, 256],stride5)\n",
    "    \n",
    "    #layer2: DeConvolution\n",
    "    weights6=tf.Variable(tf.random_normal([8,8,128,256], stddev=0.1),name='g_Wdeconv2')#weights==filters\n",
    "    bias6=tf.Variable(tf.random_normal([128],stddev=0.1), name='g_Bdeconv2')\n",
    "    stride6=2\n",
    "    deconv2=deconvolution2d(deconv1,weights6,bias6,[None, 8,8, 128],stride6)\n",
    "    \n",
    "    #layer3: DeConvolution\n",
    "    weights7=tf.Variable(tf.random_normal([6,6,64,128], stddev=0.1), name='g_Wdeconv3')#weights==filters\n",
    "    bias7=tf.Variable(tf.random_normal([64], stddev=0.1), name='g_Bdeconv3')\n",
    "    stride7=2\n",
    "    deconv3=deconvolution2d(deconv2,weights7,bias7,[None, 16,16, 64],stride7)\n",
    "    \n",
    "    #layer4: DeConvolution\n",
    "    weights9=tf.Variable(tf.random_normal([4,4,32,64], stddev=0.1),name='g_Wdeconv4')#weights==filters\n",
    "    bias9=tf.Variable(tf.random_normal([32],stddev=0.1), name='g_Bdeconv4')\n",
    "    stride9=2\n",
    "    deconv4=deconvolution2d(deconv3,weights9,bias9,[None, 32,32, 32],stride9)\n",
    "    \n",
    "    #layer5: DeConvolution\n",
    "    weights8=tf.Variable(tf.random_normal([4,4,2,32], stddev=0.1),name='g_Wdeconv5')#weights==filters\n",
    "    bias8=tf.Variable(tf.random_normal([2], stddev=0.1), name='g_Bdeconv5')\n",
    "    stride8=2\n",
    "    xOut=deconvolution2d(deconv4,weights8,bias8,[None, 64,64, 2],stride8)\n",
    "    \n",
    "    return xOut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "batch_size = 10\n",
    "sess = tf.Session()\n",
    "ImageInput = tf.placeholder(tf.float32,shape = [None, 64,64, 2])\n",
    "NoiseInput = tf.placeholder(tf.float32,shape=[None, 2,2, 16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 2)\n",
      "(?, 8, 8, 4)\n",
      "(?, 4, 4, 8)\n",
      "(?, 2, 2, 16)\n",
      "(?, 32, 32, 2)\n",
      "(?, 8, 8, 4)\n",
      "(?, 4, 4, 8)\n",
      "(?, 2, 2, 16)\n"
     ]
    }
   ],
   "source": [
    "GeneratedImage = generator(NoiseInput) #GeneratedImage holds the generated images\n",
    "\n",
    "RealImages = discriminator(ImageInput) #holds discriminator outputs (unnormalized) for the real images\n",
    "FakeImages = discriminator(GeneratedImage) #will hold the discriminator output (unnormalized) for generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build Loss\n",
    "Generator_loss = -tf.reduce_mean(tf.log(FakeImages))\n",
    "\n",
    "Discriminator_loss= -tf.reduce_mean(tf.log(RealImages) + tf.log(1. - FakeImages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# separate each network variables\n",
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate=1e-4\n",
    "# Create the Optimiser\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "optimizer_disc = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "# Create training operations on the repective netork variable only\n",
    "train_gen = optimizer_gen.minimize(Generator_loss, var_list=g_vars)\n",
    "train_disc = optimizer_disc.minimize(Discriminator_loss, var_list=d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Epoch 1: Generator Loss: 0.696716, Discriminator Loss: 1.380899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a_parida/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:31: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n",
      "/home/a_parida/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:36: DeprecationWarning: `toimage` is deprecated!\n",
      "`toimage` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use Pillow's ``Image.fromarray`` directly instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Generator Loss: 0.696772, Discriminator Loss: 1.380787\n",
      "Epoch 3: Generator Loss: 0.696829, Discriminator Loss: 1.380674\n",
      "Epoch 4: Generator Loss: 0.696885, Discriminator Loss: 1.380568\n",
      "Epoch 5: Generator Loss: 0.696943, Discriminator Loss: 1.380455\n",
      "Epoch 6: Generator Loss: 0.697001, Discriminator Loss: 1.380350\n",
      "Epoch 7: Generator Loss: 0.697059, Discriminator Loss: 1.380244\n",
      "Epoch 8: Generator Loss: 0.697117, Discriminator Loss: 1.380133\n",
      "Epoch 9: Generator Loss: 0.697173, Discriminator Loss: 1.380029\n",
      "Epoch 10: Generator Loss: 0.697231, Discriminator Loss: 1.379921\n",
      "Done...\n"
     ]
    }
   ],
   "source": [
    "trainingEpochs=10\n",
    "batchSize= 1000\n",
    "loadNum = len(velocities)\n",
    "#creating Seesion starting training\n",
    "print(\"Starting training...\")\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# lets train for all epochs\n",
    "for epoch in range(1,trainingEpochs+1):\n",
    "    batch = []\n",
    "    for currNo in range(0, batchSize):\n",
    "        r = random.randint(0, loadNum-1)\n",
    "        batch.append( velocities[r] )\n",
    "        \n",
    "    # Generate noise to feed to the generator\n",
    "    z = np.random.uniform(-1., 1., size=[batchSize, 2,2,16])\n",
    "        \n",
    "    # Train\n",
    "    fed_dict = {ImageInput: batch, NoiseInput: z}\n",
    "    t,_, _, gl, dl = sess.run([GeneratedImage,train_gen, train_disc, Generator_loss, Discriminator_loss],\n",
    "                                feed_dict=fed_dict)\n",
    "\n",
    "    if epoch % 1 == 0 or epoch == 1:\n",
    "        print('Epoch %i: Generator Loss: %f, Discriminator Loss: %f' % (epoch, gl, dl))\n",
    "\n",
    "        outDir = \"./Progress/\"\n",
    "        if not os.path.exists(outDir): \n",
    "            os.makedirs(outDir)   \n",
    "        r = random.randint(0, batchSize-1)\n",
    "        scipy.misc.toimage(np.reshape(z[r,:,:,:],(8,8)) , cmin=0.0, cmax=1.0).save(\"%s/noise_%d.png\" % (outDir,epoch))\n",
    "       # g = sess.run([GeneratedImage], feed_dict={NoiseInput:z[r:r+1,:,:,:] })\n",
    "        g = np.reshape(t[r], newshape=( 64, 64, 2))\n",
    "        generatedImage=velocityFieldToPng(g)\n",
    "\n",
    "        scipy.misc.toimage( np.reshape(generatedImage, [64, 64, 3]) , cmin=0.0, cmax=1.0).save(outDir+'/genImg_'+str(epoch)+'.png')\n",
    "\n",
    "print(\"Done...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No. Learnable Parameters for the GAN: 10003424\n"
     ]
    }
   ],
   "source": [
    "###Counting the learnable parameters\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    #print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(\"Total No. Learnable Parameters for the GAN:\",total_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
