{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data set\n",
    "with open('./data/velocity.pickle', 'rb') as handle:\n",
    "    velocities = pickle.load(handle)\n",
    "\n",
    "velocities.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build the discriminator\n",
    "\n",
    "def convolution2d(input, biases, weights, strides, padding_kind='SAME'):\n",
    "    input = tf.nn.conv2d(input, weights, [1,strides,strides,1], padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    input = tf.nn.leaky_relu(input)\n",
    "    return input\n",
    "\n",
    "def discriminator(x_image):\n",
    "    \n",
    "    #layer1: Convolution\n",
    "    weights1=tf.Variable(tf.random_normal([12,12,2,2],name='d_Wconv1', stddev=0.01))\n",
    "    #[filter_height, filter_width, in_channels, out_channels]\n",
    "    #bias=out_channels\n",
    "    bias1=tf.Variable(tf.random_normal([2], name='d_Bconv1',stddev=0.01))\n",
    "    stride1=2\n",
    "    out1=convolution2d(x_image,bias1,weights1,stride1)\n",
    "    print(out1.shape)\n",
    "    #layer2: Convolution\n",
    "    weights2=tf.Variable(tf.random_normal([6,6,2,4],name='d_Wconv2', stddev=0.01))\n",
    "    bias2=tf.Variable(tf.random_normal([4],name='d_Bconv2', stddev=0.01))\n",
    "    stride2=4\n",
    "    out2=convolution2d(out1,bias2,weights2,stride2)\n",
    "    print(out2.shape)\n",
    "    #layer3: Convolution\n",
    "    weights3=tf.Variable(tf.random_normal([4,4,4,8], name='d_Wconv3',stddev=0.01))\n",
    "    bias3=tf.Variable(tf.random_normal([8], name='d_Bconv3',stddev=0.01))\n",
    "    stride3=2\n",
    "    out3=convolution2d(out2,bias3,weights3,stride3)\n",
    "    print(out3.shape)\n",
    "    #layer4: Convolution\n",
    "    weights4=tf.Variable(tf.random_normal([3,3,8,16],name='d_Wconv4', stddev=0.01))#weights==filters\n",
    "    bias4=tf.Variable(tf.random_normal([16],name='d_Bconv4', stddev=0.01))\n",
    "    stride4=2\n",
    "    out4=convolution2d(out3,bias4,weights4,stride4)\n",
    "    print(out4.shape)\n",
    "    #layer5: Fully Connected Layer\n",
    "    out4 = tf.reshape(out4, shape=[-1, 64 ]) # flatten\n",
    "    fc_1weights = tf.Variable(tf.random_normal([64, 1], name='d_WFCN1',stddev=0.01))\n",
    "    fc_1bias   = tf.Variable(tf.random_normal([1],name='d_BFCN1', stddev=0.01))\n",
    "    fc1 = tf.add(tf.matmul(out4, fc_1weights), fc_1bias)\n",
    "    fc1 = tf.nn.tanh(fc1)\n",
    "    \n",
    "    return fc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Build the Generator\n",
    "\n",
    "def deconvolution2d(input, weights, biases,outputShape, strides, padding_kind='SAME',activation='leaky'):\n",
    "    # needed for dynamic shape with deconvolution\n",
    "    dynamicBatchSize = tf.shape(input)[0]\n",
    "    deconvShape = tf.stack([dynamicBatchSize, outputShape[1], outputShape[2], outputShape[3]])\n",
    "    input = tf.nn.conv2d_transpose(input, weights, deconvShape, [1,strides,strides,1], padding=padding_kind)\n",
    "    input = tf.nn.bias_add(input, biases)\n",
    "    if activation =='leaky':\n",
    "        input = tf.nn.leaky_relu(input)\n",
    "    elif activation=='tanh':\n",
    "        input = tf.nn.tanh(input)\n",
    "    return input\n",
    "\n",
    "def generator(noise):\n",
    "    #layer1: DeConvolution\n",
    "    weights5=tf.Variable(tf.random_normal([3,3,8,16], name='g_Wdeconv1',stddev=0.01))#weights==filters\n",
    "    #[filter_height, filter_width, in_channels, out_channels]\n",
    "    #bias=out_channels\n",
    "    bias5=tf.Variable(tf.random_normal([8],name='g_Bdeconv1', stddev=0.01))\n",
    "    stride5=2\n",
    "    deconv1=deconvolution2d(noise,weights5,bias5,[None, 4,4, 8],stride5)\n",
    "\n",
    "    #layer2: DeConvolution\n",
    "    weights6=tf.Variable(tf.random_normal([4,4,4,8],name='g_Wdeconv2', stddev=0.01))#weights==filters\n",
    "    bias6=tf.Variable(tf.random_normal([4], name='g_Bdeconv2',stddev=0.01))\n",
    "    stride6=2\n",
    "    deconv2=deconvolution2d(deconv1,weights6,bias6,[None, 8,8, 4],stride6)\n",
    "\n",
    "    #layer7: DeConvolution\n",
    "    weights7=tf.Variable(tf.random_normal([6,6,2,4], name='g_Wdeconv3', stddev=0.01))#weights==filters\n",
    "    bias7=tf.Variable(tf.random_normal([2], name='g_Bdeconv3', stddev=0.01))\n",
    "    stride7=4\n",
    "    deconv3=deconvolution2d(deconv2,weights7,bias7,[None, 32,32, 2],stride7)\n",
    "\n",
    "    #layer8: DeConvolution\n",
    "    weights8=tf.Variable(tf.random_normal([12,12,2,2],name='g_Wdeconv4', stddev=0.01))#weights==filters\n",
    "    bias8=tf.Variable(tf.random_normal([2], name='g_Bdeconv4', stddev=0.01))\n",
    "    stride8=2\n",
    "    xOut=deconvolution2d(deconv3,weights8,bias8,[None, 64,64, 2],stride8,activation='tanh')# based on GANHacks\n",
    "    \n",
    "    return xOut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training\n",
    "batch_size = 10\n",
    "sess = tf.Session()\n",
    "Disc_placeholder = tf.placeholder(tf.float32,shape = [None, 64,64, 2])\n",
    "Gen_placeholder = tf.placeholder(tf.float32,shape=[None, 2,2, 16])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 32, 32, 2)\n",
      "(?, 8, 8, 4)\n",
      "(?, 4, 4, 8)\n",
      "(?, 2, 2, 16)\n",
      "(?, 32, 32, 2)\n",
      "(?, 8, 8, 4)\n",
      "(?, 4, 4, 8)\n",
      "(?, 2, 2, 16)\n"
     ]
    }
   ],
   "source": [
    "Disc_real = discriminator(Disc_placeholder) #holds discriminator outputs (unnormalized) for the real images\n",
    "Gen_real = generator(Gen_placeholder) #Gen_real holds the generated images\n",
    "Disc_gen = discriminator(Gen_real) #will hold the discriminator output (unnormalized) for generated images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss functions\n",
    "g_loss = tf.metrics.mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Disc_gen, labels=tf.ones_like(Disc_gen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function for discriminator\n",
    "d_loss_real = tf.metrics.mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Disc_real, labels=tf.ones_like(Disc_real)))\n",
    "d_loss_fake = tf.metrics.mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Disc_gen, labels=tf.zeros_like(Disc_gen)))\n",
    "d_loss = d_loss_real+d_loss_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=(12, 12, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_1:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_2:0' shape=(6, 6, 2, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_3:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_4:0' shape=(4, 4, 4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_5:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_6:0' shape=(3, 3, 8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_7:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_8:0' shape=(64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_9:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_10:0' shape=(3, 3, 8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_11:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_12:0' shape=(4, 4, 4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_13:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_14:0' shape=(6, 6, 2, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_15:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_16:0' shape=(12, 12, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_17:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_18:0' shape=(12, 12, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_19:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_20:0' shape=(6, 6, 2, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_21:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_22:0' shape=(4, 4, 4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_23:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_24:0' shape=(3, 3, 8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_25:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_26:0' shape=(64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_27:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_28:0' shape=(12, 12, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_29:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_30:0' shape=(6, 6, 2, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_31:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_32:0' shape=(4, 4, 4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_33:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_34:0' shape=(3, 3, 8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_35:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_36:0' shape=(64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_37:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_38:0' shape=(3, 3, 8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_39:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_40:0' shape=(4, 4, 4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_41:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_42:0' shape=(6, 6, 2, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_43:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_44:0' shape=(12, 12, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_45:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_46:0' shape=(12, 12, 2, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_47:0' shape=(2,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_48:0' shape=(6, 6, 2, 4) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_49:0' shape=(4,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_50:0' shape=(4, 4, 4, 8) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_51:0' shape=(8,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_52:0' shape=(3, 3, 8, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_53:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_54:0' shape=(64, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'Variable_55:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_vars# = [var for var in tvars if 'd_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=False):\n",
    "    trainerD = tf.train.AdamOptimizer().minimize(d_loss, var_list=d_vars)\n",
    "    trainerG = tf.train.AdamOptimizer().minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total No. Learnable Parameters for the GAN: 7790\n"
     ]
    }
   ],
   "source": [
    "###Counting the learnable parameters\n",
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "        variable_parameters *= dim.value\n",
    "    #print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(\"Total No. Learnable Parameters for the GAN:\",total_parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
